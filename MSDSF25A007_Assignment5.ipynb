{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpKFYiStF6xCPlZ1x9mp61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/memrranmian/my-first-repo1/blob/main/MSDSF25A007_Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "imshtWfXllE9",
        "outputId": "4ebd6a6f-c622-4e44-92e2-576d135cdcb3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (ipython-input-664270302.py, line 23)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-664270302.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    too_high.astype(int) = clean_scores > 100\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# STEP 0: Create our student scores data\n",
        "print(\"STEP 0: Creating student scores data\")\n",
        "print(\"We're making scores for 1200 students in 5 subjects\")\n",
        "print(\"Scores will be between -1 and 102 (so we have some outliers)\")\n",
        "\n",
        "# Create random scores between -1 and 102 in integer form\n",
        "student_scores = np.random.uniform(-2, 103, size=(1200, 5)).astype(int)\n",
        "\n",
        "print(f\"Created array with shape: {student_scores.shape}\")\n",
        "print(\"This means 1200 rows (students) and 5 columns (subjects)\")\n",
        "print()\n",
        "\n",
        "# STEP 1: Replace outliers with NaN\n",
        "print(\"STEP 1: Finding and replacing outliers\")\n",
        "print(\"Outliers are scores > 100 or < 0 (impossible test scores)\")\n",
        "\n",
        "# Make a copy to keep original data safe\n",
        "clean_scores = student_scores.copy().astype(int)\n",
        "\n",
        "# Find positions where scores are too high or too low\n",
        "too_high = clean_scores > 100\n",
        "too_low. = clean_scores < 0\n",
        "\n",
        "print(f\"Found {np.sum(too_high)} scores that are too high (>100)\")\n",
        "print(f\"Found {np.sum(too_low)} scores that are too low (<0)\")\n",
        "\n",
        "# Replace outlier scores with NaN (which means 'Not a Number' - missing value)\n",
        "clean_scores[too_high] = np.nan.astype(int)\n",
        "clean_scores[too_low] = np.nan.astype(int)\n",
        "\n",
        "print(\"Replaced outliers with NaN (missing values)\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1: Weighted Imputation + Outlier Removal\n",
        "# A dataset contains student test scores for 5 subjects stored in a NumPy array of shape (1200, 5).\n",
        "# Some values are missing (NaN), and some values are outliers (> 100 or < 0).\n",
        "# Task:\n",
        "# 1. Replace outliers with NaN.\n",
        "# 2. For each subject (column), compute a weighted mean, where weights are proportional\n",
        "# to:\n",
        "# w = e^(score / max_score)\n",
        "# 3. Replace NaN values with this weighted mean (vectorized solution only).\n",
        "# 4. Return indices of students whose total score is in the top 1%.\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# STEP 0: Create the student scores data as requested\n",
        "print(\"STEP 0: Creating student scores data\")\n",
        "print(\"We need 1200 students with 5 subjects each\")\n",
        "print(\"Scores will be random integers between -1 and 102\")\n",
        "\n",
        "# Create random scores between -1 and 102 (so we have some outliers)\n",
        "student_scores = np.random.randint(-1, 103, size=(1200, 5))\n",
        "\n",
        "print(f\"Created array with shape: {student_scores.shape}\")\n",
        "print(f\"First few rows look like:\\n{student_scores[:3]}\")\n",
        "print()\n",
        "\n",
        "# STEP 1: Replace outliers with NaN\n",
        "print(\"STEP 1: Finding and replacing outliers\")\n",
        "print(\"Outliers are scores > 100 or < 0\")\n",
        "\n",
        "# Make a copy to keep original data safe\n",
        "clean_scores = student_scores.astype(float).copy()  # Convert to float to allow NaN\n",
        "\n",
        "print(\"Finding scores that are too high (>100) or too low (<0)\")\n",
        "too_high = clean_scores > 100\n",
        "too_low = clean_scores < 0\n",
        "\n",
        "print(f\"Found {np.sum(too_high)} scores that are too high\")\n",
        "print(f\"Found {np.sum(too_low)} scores that are too low\")\n",
        "\n",
        "# Replace outliers with NaN (which means \"Not a Number\" - missing value)\n",
        "clean_scores[too_high] = np.nan\n",
        "clean_scores[too_low] = np.nan\n",
        "\n",
        "print(\"Replaced outliers with NaN (missing values)\")\n",
        "print(f\"Now we have {np.sum(np.isnan(clean_scores))} missing values in total\")\n",
        "print()\n",
        "\n",
        "# STEP 2: Calculate weighted mean for each subject\n",
        "print(\"STEP 2: Calculating weighted mean for each subject\")\n",
        "print(\"Weighted mean gives more importance to higher scores\")\n",
        "print(\"We use the formula: weight = e^(score / max_score)\")\n",
        "\n",
        "# We'll calculate for each subject (column) one by one\n",
        "weighted_means = []  # Empty list to store our results\n",
        "\n",
        "# Loop through each subject (columns 0 to 4)\n",
        "for subject_index in range(5):\n",
        "    print(f\"\\n--- Working on Subject {subject_index + 1} ---\")\n",
        "\n",
        "    # Get all scores for this subject\n",
        "    subject_scores = clean_scores[:, subject_index]\n",
        "\n",
        "    # Find valid scores (not missing)\n",
        "    valid_scores = subject_scores[~np.isnan(subject_scores)]\n",
        "\n",
        "    # Find the maximum score in this subject\n",
        "    max_score = np.max(valid_scores)\n",
        "    print(f\"Maximum score in this subject: {max_score}\")\n",
        "\n",
        "    # Calculate weights using the formula: w = e^(score / max_score)\n",
        "    # e^ means exponential - it makes numbers grow faster\n",
        "    weights = np.exp(valid_scores / max_score)\n",
        "    print(f\"Calculated weights for {len(weights)} valid scores\")\n",
        "\n",
        "    # Calculate weighted mean: (sum of weight×score) ÷ (sum of weights)\n",
        "    numerator = np.sum(weights * valid_scores)  # Sum of (weight × score)\n",
        "    denominator = np.sum(weights)               # Sum of weights\n",
        "    weighted_mean = numerator / denominator\n",
        "\n",
        "    print(f\"Weighted mean for subject {subject_index + 1}: {weighted_mean:.2f}\")\n",
        "    weighted_means.append(weighted_mean)\n",
        "\n",
        "print(f\"\\nAll weighted means: {[f'{wm:.2f}' for wm in weighted_means]}\")\n",
        "print()\n",
        "\n",
        "# STEP 3: Vectorized solution to replace NaN values with weighted means\n",
        "print(\"STEP 3: Vectorized replacement of NaN values with weighted means\")\n",
        "\n",
        "# Create final scores array\n",
        "final_scores = clean_scores.copy()\n",
        "\n",
        "# Vectorized approach: Replace NaN values with weighted means for each column\n",
        "for col in range(5):\n",
        "    # Get the current column\n",
        "    current_col = clean_scores[:, col]\n",
        "\n",
        "    # Create a mask of NaN positions in this column\n",
        "    nan_mask = np.isnan(current_col)\n",
        "\n",
        "    # Vectorized replacement: Where mask is True, use weighted mean; where False, keep original value\n",
        "    final_scores[:, col] = np.where(nan_mask, weighted_means[col], current_col)\n",
        "\n",
        "print(\"Completed vectorized NaN replacement\")\n",
        "print()\n",
        "\n",
        "# STEP 4: Find top 1% students\n",
        "print(\"STEP 4: Finding top 1% students by total score\")\n",
        "\n",
        "# Calculate total score for each student (sum across all subjects)\n",
        "total_scores = np.sum(final_scores, axis=1)\n",
        "print(f\"Calculated total scores for all {len(total_scores)} students\")\n",
        "print(f\"Highest total score: {np.max(total_scores):.2f}\")\n",
        "print(f\"Lowest total score: {np.min(total_scores):.2f}\")\n",
        "\n",
        "# Calculate how many students are in top 1%\n",
        "total_students = len(total_scores)\n",
        "top_1_percent_count = max(1, total_students // 100)  # At least 1 student\n",
        "print(f\"Top 1% means {top_1_percent_count} students out of {total_students}\")\n",
        "\n",
        "# Find the threshold for top 1%\n",
        "# We sort scores and take the top ones\n",
        "sorted_indices = np.argsort(total_scores)[::-1]  # Sort from highest to lowest\n",
        "top_student_indices = sorted_indices[:top_1_percent_count]\n",
        "\n",
        "print(f\"\\nRESULT: Top {top_1_percent_count} student indices: {top_student_indices}\")\n",
        "print(\"These are the positions of the best students in our list!\")\n",
        "\n",
        "# Optional: Show their total scores\n",
        "print(f\"Their total scores are: {total_scores[top_student_indices]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgyET5-0y9A3",
        "outputId": "c2de5a90-44ed-4414-e36d-40495d8e2bff"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 0: Creating student scores data\n",
            "We need 1200 students with 5 subjects each\n",
            "Scores will be random integers between -1 and 102\n",
            "Created array with shape: (1200, 5)\n",
            "First few rows look like:\n",
            "[[ 8 40 17 60 30]\n",
            " [37 55 45  3 98]\n",
            " [48 31 47 82 48]]\n",
            "\n",
            "STEP 1: Finding and replacing outliers\n",
            "Outliers are scores > 100 or < 0\n",
            "Finding scores that are too high (>100) or too low (<0)\n",
            "Found 108 scores that are too high\n",
            "Found 56 scores that are too low\n",
            "Replaced outliers with NaN (missing values)\n",
            "Now we have 164 missing values in total\n",
            "\n",
            "STEP 2: Calculating weighted mean for each subject\n",
            "Weighted mean gives more importance to higher scores\n",
            "We use the formula: weight = e^(score / max_score)\n",
            "\n",
            "--- Working on Subject 1 ---\n",
            "Maximum score in this subject: 100.0\n",
            "Calculated weights for 1161 valid scores\n",
            "Weighted mean for subject 1: 58.00\n",
            "\n",
            "--- Working on Subject 2 ---\n",
            "Maximum score in this subject: 100.0\n",
            "Calculated weights for 1168 valid scores\n",
            "Weighted mean for subject 2: 58.00\n",
            "\n",
            "--- Working on Subject 3 ---\n",
            "Maximum score in this subject: 100.0\n",
            "Calculated weights for 1174 valid scores\n",
            "Weighted mean for subject 3: 57.97\n",
            "\n",
            "--- Working on Subject 4 ---\n",
            "Maximum score in this subject: 100.0\n",
            "Calculated weights for 1171 valid scores\n",
            "Weighted mean for subject 4: 57.82\n",
            "\n",
            "--- Working on Subject 5 ---\n",
            "Maximum score in this subject: 100.0\n",
            "Calculated weights for 1162 valid scores\n",
            "Weighted mean for subject 5: 58.44\n",
            "\n",
            "All weighted means: ['58.00', '58.00', '57.97', '57.82', '58.44']\n",
            "\n",
            "STEP 3: Vectorized replacement of NaN values with weighted means\n",
            "Completed vectorized NaN replacement\n",
            "\n",
            "STEP 4: Finding top 1% students by total score\n",
            "Calculated total scores for all 1200 students\n",
            "Highest total score: 435.00\n",
            "Lowest total score: 50.00\n",
            "Top 1% means 12 students out of 1200\n",
            "\n",
            "RESULT: Top 12 student indices: [ 955  595   60  553  661   31  275  936  982  162  262 1107]\n",
            "These are the positions of the best students in our list!\n",
            "Their total scores are: [435.         434.         431.         422.         413.\n",
            " 411.         406.         400.00010088 400.         398.\n",
            " 397.         396.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2: Conditional Imputation Based on Student Group\n",
        "# A dataset (900, 5) contains:\n",
        "# • Columns: Math, Physics, English, CS, Chemistry\n",
        "# • NaN values exist randomly.\n",
        "# Students are divided into 3 groups:\n",
        "# • Group A: rows 0–299\n",
        "# • Group B: rows 300–599\n",
        "# • Group C: rows 600–899\n",
        "# Task:\n",
        "# Impute values using different strategies per group:\n",
        "# • Group A: Replace NaNs with row mean.\n",
        "# • Group B: Replace NaNs with column median.\n",
        "# • Group C: Replace NaNs with global median of all non-NaN values.\n",
        "# Return:\n",
        "# • Mean score of each group\n",
        "# • Group with highest average Math performance\n",
        "# Must be fully vectorized — no loops.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# STEP 1: Create sample student data with missing values\n",
        "print(\"STEP 1: Creating student data\")\n",
        "print(\"We have 900 students with 5 subjects: Math, Physics, English, CS, Chemistry\")\n",
        "\n",
        "# Create random scores between 50-100 with some missing values\n",
        "student_scores = np.random.randint(50, 101, size=(900, 5)).astype(float)\n",
        "\n",
        "# Add some missing values (NaN) randomly\n",
        "mask = np.random.random(size=(900, 5)) < 0.1  # 10% chance of missing value\n",
        "student_scores[mask] = np.nan\n",
        "\n",
        "print(f\"Created array shape: {student_scores.shape}\")\n",
        "print(f\"Number of missing values: {np.sum(np.isnan(student_scores))}\")\n",
        "print()\n",
        "\n",
        "# STEP 2: Define the student groups\n",
        "print(\"STEP 2: Defining student groups\")\n",
        "print(\"Group A: Students 0 to 299 (first 300 students)\")\n",
        "print(\"Group B: Students 300 to 599 (next 300 students)\")\n",
        "print(\"Group C: Students 600 to 899 (last 300 students)\")\n",
        "\n",
        "# Create group masks (these are like highlighters for each group)\n",
        "group_a_mask = np.zeros(900, dtype=bool)  # Create empty mask for Group A\n",
        "group_a_mask[0:300] = True                # Highlight students 0-299\n",
        "\n",
        "group_b_mask = np.zeros(900, dtype=bool)  # Create empty mask for Group B\n",
        "group_b_mask[300:600] = True              # Highlight students 300-599\n",
        "\n",
        "group_c_mask = np.zeros(900, dtype=bool)  # Create empty mask for Group C\n",
        "group_c_mask[600:900] = True              # Highlight students 600-899\n",
        "\n",
        "print(f\"Group A has {np.sum(group_a_mask)} students\")\n",
        "print(f\"Group B has {np.sum(group_b_mask)} students\")\n",
        "print(f\"Group C has {np.sum(group_c_mask)} students\")\n",
        "print()\n",
        "\n",
        "# STEP 3: Group A - Replace NaNs with row mean\n",
        "print(\"STEP 3: Group A - Replace missing values with each student's average\")\n",
        "\n",
        "# Make a copy to work with\n",
        "filled_scores = student_scores.copy()\n",
        "\n",
        "# For Group A students only\n",
        "group_a_scores = filled_scores[group_a_mask]\n",
        "\n",
        "# Calculate each student's average (ignoring missing values)\n",
        "row_means = np.nanmean(group_a_scores, axis=1, keepdims=True)\n",
        "\n",
        "# Find where values are missing in Group A\n",
        "nan_mask_a = np.isnan(group_a_scores)\n",
        "\n",
        "# Replace missing values with row means\n",
        "# np.where works like: if condition True use value1, else use value2\n",
        "group_a_scores_filled = np.where(nan_mask_a, row_means, group_a_scores)\n",
        "\n",
        "# Put the filled scores back\n",
        "filled_scores[group_a_mask] = group_a_scores_filled\n",
        "\n",
        "print(\"Group A: Missing values replaced with each student's average\")\n",
        "print()\n",
        "\n",
        "# STEP 4: Group B - Replace NaNs with column median\n",
        "print(\"STEP 4: Group B - Replace missing values with subject medians\")\n",
        "\n",
        "# For Group B students only\n",
        "group_b_scores = filled_scores[group_b_mask]\n",
        "\n",
        "# Calculate median for each subject (ignoring missing values)\n",
        "column_medians = np.nanmedian(group_b_scores, axis=0, keepdims=True)\n",
        "\n",
        "# Find where values are missing in Group B\n",
        "nan_mask_b = np.isnan(group_b_scores)\n",
        "\n",
        "# Replace missing values with column medians\n",
        "group_b_scores_filled = np.where(nan_mask_b, column_medians, group_b_scores)\n",
        "\n",
        "# Put the filled scores back\n",
        "filled_scores[group_b_mask] = group_b_scores_filled\n",
        "\n",
        "print(\"Group B: Missing values replaced with subject medians\")\n",
        "print()\n",
        "\n",
        "# STEP 5: Group C - Replace NaNs with global median\n",
        "print(\"STEP 5: Group C - Replace missing values with global median\")\n",
        "\n",
        "# For Group C students only\n",
        "group_c_scores = filled_scores[group_c_mask]\n",
        "\n",
        "# Calculate global median of all non-missing values\n",
        "global_median = np.nanmedian(filled_scores)\n",
        "\n",
        "# Find where values are missing in Group C\n",
        "nan_mask_c = np.isnan(group_c_scores)\n",
        "\n",
        "# Replace missing values with global median\n",
        "group_c_scores_filled = np.where(nan_mask_c, global_median, group_c_scores)\n",
        "\n",
        "# Put the filled scores back\n",
        "filled_scores[group_c_mask] = group_c_scores_filled\n",
        "\n",
        "print(f\"Global median (all subjects): {global_median:.2f}\")\n",
        "print(\"Group C: Missing values replaced with global median\")\n",
        "print()\n",
        "\n",
        "# STEP 6: Calculate mean scores for each group\n",
        "print(\"STEP 6: Calculate average scores for each group\")\n",
        "\n",
        "# Calculate mean for Group A (all subjects)\n",
        "mean_group_a = np.mean(filled_scores[group_a_mask])\n",
        "print(f\"Group A average score: {mean_group_a:.2f}\")\n",
        "\n",
        "# Calculate mean for Group B (all subjects)\n",
        "mean_group_b = np.mean(filled_scores[group_b_mask])\n",
        "print(f\"Group B average score: {mean_group_b:.2f}\")\n",
        "\n",
        "# Calculate mean for Group C (all subjects)\n",
        "mean_group_c = np.mean(filled_scores[group_c_mask])\n",
        "print(f\"Group C average score: {mean_group_c:.2f}\")\n",
        "print()\n",
        "\n",
        "# STEP 7: Find group with highest Math performance\n",
        "print(\"STEP 7: Find which group has best Math scores\")\n",
        "\n",
        "# Get Math scores (first column) for each group\n",
        "math_scores_a = filled_scores[group_a_mask, 0]  # Math is column 0\n",
        "math_scores_b = filled_scores[group_b_mask, 0]\n",
        "math_scores_c = filled_scores[group_c_mask, 0]\n",
        "\n",
        "# Calculate Math averages\n",
        "math_mean_a = np.mean(math_scores_a)\n",
        "math_mean_b = np.mean(math_scores_b)\n",
        "math_mean_c = np.mean(math_scores_c)\n",
        "\n",
        "print(f\"Group A Math average: {math_mean_a:.2f}\")\n",
        "print(f\"Group B Math average: {math_mean_b:.2f}\")\n",
        "print(f\"Group C Math average: {math_mean_c:.2f}\")\n",
        "\n",
        "# Find which group has highest Math average\n",
        "math_means = [math_mean_a, math_mean_b, math_mean_c]\n",
        "best_group_index = np.argmax(math_means)\n",
        "best_group_name = [\"A\", \"B\", \"C\"][best_group_index]\n",
        "\n",
        "print(f\"\\nRESULT: Group {best_group_name} has the highest Math performance!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXLqCwG9ziV3",
        "outputId": "2939cdbc-087d-4091-8828-60c69c3e8141"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Creating student data\n",
            "We have 900 students with 5 subjects: Math, Physics, English, CS, Chemistry\n",
            "Created array shape: (900, 5)\n",
            "Number of missing values: 495\n",
            "\n",
            "STEP 2: Defining student groups\n",
            "Group A: Students 0 to 299 (first 300 students)\n",
            "Group B: Students 300 to 599 (next 300 students)\n",
            "Group C: Students 600 to 899 (last 300 students)\n",
            "Group A has 300 students\n",
            "Group B has 300 students\n",
            "Group C has 300 students\n",
            "\n",
            "STEP 3: Group A - Replace missing values with each student's average\n",
            "Group A: Missing values replaced with each student's average\n",
            "\n",
            "STEP 4: Group B - Replace missing values with subject medians\n",
            "Group B: Missing values replaced with subject medians\n",
            "\n",
            "STEP 5: Group C - Replace missing values with global median\n",
            "Global median (all subjects): 75.00\n",
            "Group C: Missing values replaced with global median\n",
            "\n",
            "STEP 6: Calculate average scores for each group\n",
            "Group A average score: 74.27\n",
            "Group B average score: 75.37\n",
            "Group C average score: 75.15\n",
            "\n",
            "STEP 7: Find which group has best Math scores\n",
            "Group A Math average: 73.24\n",
            "Group B Math average: 75.56\n",
            "Group C Math average: 75.30\n",
            "\n",
            "RESULT: Group B has the highest Math performance!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3: Multi-Level Integrity Check + Replacement\n",
        "# You have a (1500, 5) score matrix with:\n",
        "# • Some scores missing (NaN)\n",
        "# • Some scores duplicated (e.g., same value repeated in entire row)\n",
        "# Task:\n",
        "# 1. Detect rows where any 3+ columns have the same score → treat the entire row as\n",
        "# invalid.\n",
        "# 2. Replace such rows using the mean vector of all valid rows.\n",
        "# 3. After cleaning, compute percentile rankings (0–100) for each student based on total\n",
        "# scores.\n",
        "# Output an array of percentile ranks of shape (1500,).\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# STEP 1: Create sample student data\n",
        "print(\"STEP 1: Creating student score data\")\n",
        "print(\"1500 students, 5 subjects with some missing and duplicated values\")\n",
        "\n",
        "# Create random scores between 60-100\n",
        "student_scores = np.random.randint(60, 101, size=(1500, 5)).astype(float)\n",
        "\n",
        "# Add some missing values (NaN)\n",
        "missing_mask = np.random.random(size=(1500, 5)) < 0.05  # 5% missing\n",
        "student_scores[missing_mask] = np.nan\n",
        "\n",
        "# Add some duplicated rows (where 3+ subjects have same score)\n",
        "for i in range(50):  # Make 50 students have suspicious scores\n",
        "    student_idx = np.random.randint(0, 1500)\n",
        "    duplicate_value = np.random.randint(60, 101)\n",
        "    # Make 3 or more subjects have the same score\n",
        "    subjects_to_duplicate = np.random.choice(5, size=3, replace=False)\n",
        "    student_scores[student_idx, subjects_to_duplicate] = duplicate_value\n",
        "\n",
        "print(f\"Created scores for {student_scores.shape[0]} students, {student_scores.shape[1]} subjects\")\n",
        "print(f\"Missing values: {np.sum(np.isnan(student_scores))}\")\n",
        "print()\n",
        "\n",
        "# STEP 2: Detect rows with 3+ same scores\n",
        "print(\"STEP 2: Finding suspicious rows with 3+ same scores\")\n",
        "print(\"This detects possible cheating or data errors\")\n",
        "\n",
        "# Make a copy to clean missing values temporarily for detection\n",
        "temp_scores = student_scores.copy()\n",
        "temp_scores[np.isnan(temp_scores)] = -999  # Replace NaN with special value\n",
        "\n",
        "# Check each row for duplicates\n",
        "suspicious_rows = []  # List to store bad row indices\n",
        "\n",
        "for i in range(len(temp_scores)):\n",
        "    row = temp_scores[i]  # Get one student's scores\n",
        "    unique_scores, counts = np.unique(row, return_counts=True)  # Count each score\n",
        "\n",
        "    # Check if any score appears 3 or more times (and ignore our special -999 value)\n",
        "    valid_counts = counts[unique_scores != -999]\n",
        "    if len(valid_counts) > 0 and np.max(valid_counts) >= 3:\n",
        "        suspicious_rows.append(i)\n",
        "\n",
        "print(f\"Found {len(suspicious_rows)} suspicious rows with 3+ same scores\")\n",
        "print(f\"Suspicious row indices: {suspicious_rows[:10]}...\")  # Show first 10\n",
        "print()\n",
        "\n",
        "# STEP 3: Replace suspicious rows with mean of valid rows\n",
        "print(\"STEP 3: Replacing suspicious rows with average of good rows\")\n",
        "\n",
        "# Find valid rows (not suspicious)\n",
        "valid_rows_mask = np.ones(1500, dtype=bool)  # Start with all True\n",
        "valid_rows_mask[suspicious_rows] = False     # Mark suspicious rows as False\n",
        "\n",
        "# Calculate mean of each subject from valid rows (ignoring NaN)\n",
        "valid_scores = student_scores[valid_rows_mask]\n",
        "subject_means = np.nanmean(valid_scores, axis=0)\n",
        "\n",
        "print(f\"Subject means from good rows: {subject_means}\")\n",
        "\n",
        "# Replace each suspicious row with the subject means\n",
        "cleaned_scores = student_scores.copy()\n",
        "for row_idx in suspicious_rows:\n",
        "    cleaned_scores[row_idx] = subject_means  # Replace entire row with means\n",
        "\n",
        "print(f\"Replaced {len(suspicious_rows)} suspicious rows\")\n",
        "print()\n",
        "\n",
        "# STEP 4: Calculate percentile rankings\n",
        "print(\"STEP 4: Calculating percentile rankings (0-100)\")\n",
        "print(\"Percentile shows how each student compares to others\")\n",
        "\n",
        "# Calculate total score for each student (sum of all subjects)\n",
        "total_scores = np.nansum(cleaned_scores, axis=1)\n",
        "\n",
        "print(f\"Total scores range: {np.min(total_scores):.1f} to {np.max(total_scores):.1f}\")\n",
        "\n",
        "# Calculate percentile for each student\n",
        "percentile_ranks = np.zeros(1500)  # Create empty array for results\n",
        "\n",
        "for i in range(1500):\n",
        "    # Percentile = (number of students with lower scores / total students) × 100\n",
        "    student_score = total_scores[i]\n",
        "    students_with_lower_score = np.sum(total_scores < student_score)\n",
        "    percentile = (students_with_lower_score / 1500) * 100\n",
        "    percentile_ranks[i] = percentile\n",
        "\n",
        "print(f\"Percentile ranks calculated: {percentile_ranks.shape}\")\n",
        "print(f\"Percentiles range: {np.min(percentile_ranks):.1f} to {np.max(percentile_ranks):.1f}\")\n",
        "print()\n",
        "\n",
        "# STEP 5: Show results\n",
        "print(\"STEP 5: Final Results\")\n",
        "print(f\"Original suspicious rows: {len(suspicious_rows)}\")\n",
        "print(f\"Percentile array shape: {percentile_ranks.shape}\")\n",
        "print(f\"First 10 percentile values: {percentile_ranks[:10]}\")\n",
        "print(\"\\nExample: A percentile of 85 means the student scored better than 85% of students\")\n",
        "print(\"Example: A percentile of 25 means the student scored better than only 25% of students\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn-nUP_-2kh_",
        "outputId": "2b79fb4f-293d-464d-fde4-248234718172"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Creating student score data\n",
            "1500 students, 5 subjects with some missing and duplicated values\n",
            "Created scores for 1500 students, 5 subjects\n",
            "Missing values: 382\n",
            "\n",
            "STEP 2: Finding suspicious rows with 3+ same scores\n",
            "This detects possible cheating or data errors\n",
            "Found 57 suspicious rows with 3+ same scores\n",
            "Suspicious row indices: [8, 31, 66, 127, 196, 234, 309, 356, 367, 406]...\n",
            "\n",
            "STEP 3: Replacing suspicious rows with average of good rows\n",
            "Subject means from good rows: [80.62417097 80.21945867 79.34956395 80.51169591 79.49671293]\n",
            "Replaced 57 suspicious rows\n",
            "\n",
            "STEP 4: Calculating percentile rankings (0-100)\n",
            "Percentile shows how each student compares to others\n",
            "Total scores range: 160.0 to 475.0\n",
            "Percentile ranks calculated: (1500,)\n",
            "Percentiles range: 0.0 to 99.9\n",
            "\n",
            "STEP 5: Final Results\n",
            "Original suspicious rows: 57\n",
            "Percentile array shape: (1500,)\n",
            "First 10 percentile values: [24.53333333  5.86666667 47.66666667 91.53333333 83.4        62.93333333\n",
            " 84.66666667 21.66666667 59.13333333 26.4       ]\n",
            "\n",
            "Example: A percentile of 85 means the student scored better than 85% of students\n",
            "Example: A percentile of 25 means the student scored better than only 25% of students\n",
            "[[67. 66. 63. 69. 90.]\n",
            " [68. 86. 61. 78. nan]\n",
            " [98. 67. 63. 75. 88.]\n",
            " ...\n",
            " [71. 75. 89. 74. 61.]\n",
            " [64. 60. 93. nan 98.]\n",
            " [66. 93. 81. 81. 64.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4 — Finding Students With Suspicious Patterns\n",
        "# You have a dataset (1100, 5) containing:\n",
        "# • Exam 1 scores (columns 0–2)\n",
        "# • Practical scores (columns 3–4)\n",
        "# Task:\n",
        "# • Replace NaNs using the column-wise mean.\n",
        "# • Compute the coefficient of variation (std/mean) for each student across all 5 subjects.\n",
        "# • Mark students as suspicious if:\n",
        "# (Mean Exam Score > 85) AND (Std of Practicals > 20)\n",
        "# 1. Return percentage of suspicious students.\n",
        "# Must use NumPy boolean indexing only.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# STEP 1: Create sample student data\n",
        "print(\"STEP 1: Creating student data\")\n",
        "print(\"1100 students: 3 Exam scores + 2 Practical scores\")\n",
        "\n",
        "# Create random scores\n",
        "student_scores = np.random.randint(40, 101, size=(1100, 5)).astype(float)\n",
        "\n",
        "# Add some missing values (NaN)\n",
        "missing_mask = np.random.random(size=(1100, 5)) < 0.08  # 8% missing\n",
        "student_scores[missing_mask] = np.nan\n",
        "\n",
        "print(f\"Created {student_scores.shape[0]} students, {student_scores.shape[1]} scores\")\n",
        "print(f\"Missing values: {np.sum(np.isnan(student_scores))}\")\n",
        "print()\n",
        "\n",
        "# STEP 2: Replace NaN with column means\n",
        "print(\"STEP 2: Replacing missing values with column averages\")\n",
        "\n",
        "# Make a copy to work with\n",
        "filled_scores = student_scores.copy()\n",
        "\n",
        "# Calculate mean for each column (subject)\n",
        "column_means = np.nanmean(filled_scores, axis=0)\n",
        "\n",
        "print(f\"Column means: {column_means}\")\n",
        "\n",
        "# Find where values are missing\n",
        "missing_positions = np.isnan(filled_scores)\n",
        "\n",
        "# Replace missing values with column means\n",
        "filled_scores[missing_positions] = np.take(column_means, np.where(missing_positions)[1])\n",
        "\n",
        "print(\"All missing values replaced with column averages\")\n",
        "print()\n",
        "\n",
        "# STEP 3: Calculate coefficient of variation for each student\n",
        "print(\"STEP 3: Calculating variation coefficient for each student\")\n",
        "print(\"Variation coefficient = Standard Deviation / Mean\")\n",
        "print(\"Shows how consistent a student's scores are\")\n",
        "\n",
        "# Calculate mean for each student (across all 5 subjects)\n",
        "student_means = np.mean(filled_scores, axis=1)\n",
        "\n",
        "# Calculate standard deviation for each student (across all 5 subjects)\n",
        "student_stds = np.std(filled_scores, axis=1)\n",
        "\n",
        "# Calculate coefficient of variation for each student\n",
        "coefficient_of_variation = student_stds / student_means\n",
        "\n",
        "print(f\"Calculated variation coefficients for all 1100 students\")\n",
        "print(f\"Example coefficients: {coefficient_of_variation[:5]}\")\n",
        "print()\n",
        "\n",
        "# STEP 4: Identify suspicious students\n",
        "print(\"STEP 4: Finding suspicious students\")\n",
        "print(\"Suspicious if: (Exam Mean > 85) AND (Practical Std > 20)\")\n",
        "\n",
        "# Separate Exam scores (columns 0-2) and Practical scores (columns 3-4)\n",
        "exam_scores = filled_scores[:, 0:3]   # First 3 columns\n",
        "practical_scores = filled_scores[:, 3:5]  # Last 2 columns\n",
        "\n",
        "# Calculate mean of Exam scores for each student\n",
        "exam_means = np.mean(exam_scores, axis=1)\n",
        "\n",
        "# Calculate standard deviation of Practical scores for each student\n",
        "practical_stds = np.std(practical_scores, axis=1)\n",
        "\n",
        "print(f\"Exam means range: {np.min(exam_means):.1f} to {np.max(exam_means):.1f}\")\n",
        "print(f\"Practical stds range: {np.min(practical_stds):.1f} to {np.max(practical_stds):.1f}\")\n",
        "\n",
        "# Create boolean conditions for suspicious students\n",
        "condition1 = exam_means > 85   # Students with high exam averages\n",
        "condition2 = practical_stds > 20  # Students with inconsistent practicals\n",
        "\n",
        "print(f\"Students with Exam Mean > 85: {np.sum(condition1)}\")\n",
        "print(f\"Students with Practical Std > 20: {np.sum(condition2)}\")\n",
        "\n",
        "# Find suspicious students using boolean indexing\n",
        "suspicious_students = condition1 & condition2  # Both conditions must be True\n",
        "\n",
        "print(f\"Suspicious students found: {np.sum(suspicious_students)}\")\n",
        "print()\n",
        "\n",
        "# STEP 5: Calculate percentage of suspicious students\n",
        "print(\"STEP 5: Calculating percentage\")\n",
        "\n",
        "total_students = len(filled_scores)\n",
        "suspicious_count = np.sum(suspicious_students)\n",
        "percentage_suspicious = (suspicious_count / total_students) * 100\n",
        "\n",
        "print(f\"Total students: {total_students}\")\n",
        "print(f\"Suspicious students: {suspicious_count}\")\n",
        "print(f\"Percentage suspicious: {percentage_suspicious:.2f}%\")\n",
        "\n",
        "print(f\"\\nFINAL RESULT: {percentage_suspicious:.2f}% of students are suspicious\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iydpvHLe6TzV",
        "outputId": "2a408365-63cf-4de4-8bce-971b039bd912"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Creating student data\n",
            "1100 students: 3 Exam scores + 2 Practical scores\n",
            "Created 1100 students, 5 scores\n",
            "Missing values: 434\n",
            "\n",
            "STEP 2: Replacing missing values with column averages\n",
            "Column means: [69.57199211 69.6023622  69.41090555 69.94257426 70.73773774]\n",
            "All missing values replaced with column averages\n",
            "\n",
            "STEP 3: Calculating variation coefficient for each student\n",
            "Variation coefficient = Standard Deviation / Mean\n",
            "Shows how consistent a student's scores are\n",
            "Calculated variation coefficients for all 1100 students\n",
            "Example coefficients: [0.20700783 0.27385016 0.26126713 0.19614948 0.24888761]\n",
            "\n",
            "STEP 4: Finding suspicious students\n",
            "Suspicious if: (Exam Mean > 85) AND (Practical Std > 20)\n",
            "Exam means range: 42.3 to 98.7\n",
            "Practical stds range: 0.0 to 30.0\n",
            "Students with Exam Mean > 85: 64\n",
            "Students with Practical Std > 20: 102\n",
            "Suspicious students found: 5\n",
            "\n",
            "STEP 5: Calculating percentage\n",
            "Total students: 1100\n",
            "Suspicious students: 5\n",
            "Percentage suspicious: 0.45%\n",
            "\n",
            "FINAL RESULT: 0.45% of students are suspicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5: Detecting Students With Unusual Performance Patterns\n",
        "# You have a dataset of shape (1100, 5) representing students' scores:\n",
        "# • Columns 0–1: Midterm scores\n",
        "# • Columns 2–3: Final exam scores\n",
        "# • Column 4: Project score\n",
        "# Some values are missing and need to be cleaned.\n",
        "# Task\n",
        "# 1. Replace NaNs using column-wise median\n",
        "# Use NumPy operations (no loops, no pandas) to fill missing values:\n",
        "# NaN → column_median\n",
        "# 2. Compute \"Performance Stability Score\" for each student\n",
        "# For each row:\n",
        "# stability_score = std(row) / max(row)\n",
        "# (Use NumPy std and max across axis=1)\n",
        "# 3. Mark students as flagged if they show unusual performance\n",
        "# A student is flagged if:\n",
        "# (Average Final Exam Score > 90) AND (Project Score < 50) AND\n",
        "# (stability_score > 0.25)\n",
        "# Where:\n",
        "# • Average Final Exam Score = mean(columns 2 and 3)\n",
        "# • Project Score = column 4\n",
        "# Use boolean masking and vector operations only.\n",
        "# 4. Return the percentage of flagged students\n",
        "# Compute:\n",
        "# percentage = (flagged_count / 1100) * 100\n",
        "# Return the final numeric value.\n",
        "# Constraints\n",
        "# • Use NumPy-only operations\n",
        "# • Use boolean indexing\n",
        "# • No explicit Python loops\n",
        "# • No pandas or sklearn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# STEP 1: Create sample student data\n",
        "print(\"STEP 1: Creating student score data\")\n",
        "print(\"1100 students with:\")\n",
        "print(\"- Columns 0-1: Midterm exams\")\n",
        "print(\"- Columns 2-3: Final exams\")\n",
        "print(\"- Column 4: Project score\")\n",
        "\n",
        "# Create random scores\n",
        "student_scores = np.random.randint(30, 101, size=(1100, 5)).astype(float)\n",
        "\n",
        "# Add some missing values (NaN)\n",
        "missing_mask = np.random.random(size=(1100, 5)) < 0.07  # 7% missing\n",
        "student_scores[missing_mask] = np.nan\n",
        "\n",
        "print(f\"Created {student_scores.shape[0]} students, {student_scores.shape[1]} scores\")\n",
        "print(f\"Missing values: {np.sum(np.isnan(student_scores))}\")\n",
        "print()\n",
        "\n",
        "# STEP 2: Replace NaN with column medians\n",
        "print(\"STEP 2: Replacing missing values with column medians\")\n",
        "\n",
        "# Make a copy to work with\n",
        "filled_scores = student_scores.copy()\n",
        "\n",
        "# Calculate median for each column (subject)\n",
        "# Median = middle value when sorted\n",
        "column_medians = np.nanmedian(filled_scores, axis=0)\n",
        "\n",
        "print(f\"Column medians: {column_medians}\")\n",
        "\n",
        "# Find where values are missing\n",
        "missing_positions = np.isnan(filled_scores)\n",
        "\n",
        "# Replace missing values with column medians\n",
        "# This is vectorized - no loops!\n",
        "filled_scores[missing_positions] = np.take(column_medians, np.where(missing_positions)[1])\n",
        "\n",
        "print(\"All missing values replaced with column medians\")\n",
        "print()\n",
        "\n",
        "# STEP 3: Calculate Performance Stability Score\n",
        "print(\"STEP 3: Calculating Performance Stability Score\")\n",
        "print(\"Stability Score = Standard Deviation / Maximum Score\")\n",
        "print(\"Lower score = more consistent performance\")\n",
        "\n",
        "# Calculate standard deviation for each student (across all 5 scores)\n",
        "student_std = np.std(filled_scores, axis=1)\n",
        "\n",
        "# Calculate maximum score for each student (highest of their 5 scores)\n",
        "student_max = np.max(filled_scores, axis=1)\n",
        "\n",
        "# Calculate stability score: std / max\n",
        "stability_scores = student_std / student_max\n",
        "\n",
        "print(f\"Calculated stability scores for all 1100 students\")\n",
        "print(f\"Stability scores range: {np.min(stability_scores):.3f} to {np.max(stability_scores):.3f}\")\n",
        "print()\n",
        "\n",
        "# STEP 4: Identify flagged students using boolean conditions\n",
        "print(\"STEP 4: Finding flagged students with unusual patterns\")\n",
        "print(\"Flagged if ALL conditions are True:\")\n",
        "print(\"1. Final Exam Average > 90\")\n",
        "print(\"2. Project Score < 50\")\n",
        "print(\"3. Stability Score > 0.25\")\n",
        "\n",
        "# Get Final Exam scores (columns 2-3)\n",
        "final_exam_scores = filled_scores[:, 2:4]\n",
        "\n",
        "# Calculate average of Final Exam scores for each student\n",
        "final_exam_means = np.mean(final_exam_scores, axis=1)\n",
        "\n",
        "# Get Project scores (column 4)\n",
        "project_scores = filled_scores[:, 4]\n",
        "\n",
        "print(f\"Final exam averages range: {np.min(final_exam_means):.1f} to {np.max(final_exam_means):.1f}\")\n",
        "print(f\"Project scores range: {np.min(project_scores):.1f} to {np.max(project_scores):.1f}\")\n",
        "print(f\"Stability scores range: {np.min(stability_scores):.3f} to {np.max(stability_scores):.3f}\")\n",
        "\n",
        "# Create boolean conditions for flagged students\n",
        "condition1 = final_exam_means > 90    # High final exam performance\n",
        "condition2 = project_scores < 50      # Low project score\n",
        "condition3 = stability_scores > 0.25  # High variability\n",
        "\n",
        "print(f\"Students with Final Exam > 90: {np.sum(condition1)}\")\n",
        "print(f\"Students with Project < 50: {np.sum(condition2)}\")\n",
        "print(f\"Students with Stability > 0.25: {np.sum(condition3)}\")\n",
        "\n",
        "# Combine all conditions using AND (&)\n",
        "# All three must be True for a student to be flagged\n",
        "flagged_students = condition1 & condition2 & condition3\n",
        "\n",
        "print(f\"Flagged students found: {np.sum(flagged_students)}\")\n",
        "print()\n",
        "\n",
        "# STEP 5: Calculate percentage of flagged students\n",
        "print(\"STEP 5: Calculating percentage of flagged students\")\n",
        "\n",
        "total_students = len(filled_scores)\n",
        "flagged_count = np.sum(flagged_students)\n",
        "percentage_flagged = (flagged_count / total_students) * 100\n",
        "\n",
        "print(f\"Total students: {total_students}\")\n",
        "print(f\"Flagged students: {flagged_count}\")\n",
        "print(f\"Percentage flagged: {percentage_flagged:.2f}%\")\n",
        "\n",
        "print(f\"\\nFINAL RESULT: {percentage_flagged:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPAaKY3c7oQR",
        "outputId": "752614b8-8b0f-45b3-da66-fbca23f91e33"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Creating student score data\n",
            "1100 students with:\n",
            "- Columns 0-1: Midterm exams\n",
            "- Columns 2-3: Final exams\n",
            "- Column 4: Project score\n",
            "Created 1100 students, 5 scores\n",
            "Missing values: 366\n",
            "\n",
            "STEP 2: Replacing missing values with column medians\n",
            "Column medians: [66. 65. 65. 66. 66.]\n",
            "All missing values replaced with column medians\n",
            "\n",
            "STEP 3: Calculating Performance Stability Score\n",
            "Stability Score = Standard Deviation / Maximum Score\n",
            "Lower score = more consistent performance\n",
            "Calculated stability scores for all 1100 students\n",
            "Stability scores range: 0.024 to 0.312\n",
            "\n",
            "STEP 4: Finding flagged students with unusual patterns\n",
            "Flagged if ALL conditions are True:\n",
            "1. Final Exam Average > 90\n",
            "2. Project Score < 50\n",
            "3. Stability Score > 0.25\n",
            "Final exam averages range: 32.0 to 99.0\n",
            "Project scores range: 30.0 to 100.0\n",
            "Stability scores range: 0.024 to 0.312\n",
            "Students with Final Exam > 90: 43\n",
            "Students with Project < 50: 255\n",
            "Students with Stability > 0.25: 70\n",
            "Flagged students found: 4\n",
            "\n",
            "STEP 5: Calculating percentage of flagged students\n",
            "Total students: 1100\n",
            "Flagged students: 4\n",
            "Percentage flagged: 0.36%\n",
            "\n",
            "FINAL RESULT: 0.36%\n"
          ]
        }
      ]
    }
  ]
}